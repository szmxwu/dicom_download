# -*- coding: utf-8 -*-
#!/usr/bin/env python3
"""
DICOM Processing System - Client Side Test Script
Usage: python test.py <AccessionNumber> [--output_dir ./downloads] [--format nifti|npz]
"""

import requests
import time
import os
import sys
import argparse
import zipfile
import shutil
from tqdm import tqdm
import pandas as pd
import json
from datetime import datetime, timedelta
import tempfile

SERVER_URL = "http://172.17.250.136:5005"
API_SINGLE = f"{SERVER_URL}/api/process/single"
API_STATUS = lambda task_id: f"{SERVER_URL}/api/task/{task_id}/status"
API_DOWNLOAD = lambda task_id: f"{SERVER_URL}/api/download/{task_id}/zip"

def poll_task_status(task_id):
    """è½®è¯¢ä»»åŠ¡çŠ¶æ€ç›´åˆ°å®Œæˆæˆ–å¤±è´¥"""
    print(f"[*] æ­£åœ¨ç›‘æ§ä»»åŠ¡: {task_id}")
    last_log_idx = 0
    
    while True:
        try:
            response = requests.get(API_STATUS(task_id))
            if response.status_code != 200:
                print(f"[!] è·å–çŠ¶æ€å¤±è´¥: {response.text}")
                return False, None
            
            data = response.json()
            status = data.get('status')
            progress = data.get('progress', 0)
            step = data.get('current_step', '')
            logs = data.get('logs', [])
            
            # æ‰“å°æ–°æ—¥å¿—
            if len(logs) > last_log_idx:
                for log in logs[last_log_idx:]:
                    print(f"  [{log['timestamp']}] {log['message']}")
                last_log_idx = len(logs)
            
            # æ‰“å°è¿›åº¦ä¿¡æ¯
            sys.stdout.write(f"\r    è¿›åº¦: [{progress}%] æ­¥éª¤: {step} ".ljust(60))
            sys.stdout.flush()
            
            if status == 'completed':
                print("\n[+] ä»»åŠ¡å¤„ç†æˆåŠŸå®Œæˆï¼")
                return True, data.get('result')
            elif status == 'failed':
                print(f"\n[!] ä»»åŠ¡å¤±è´¥: {data.get('error')}")
                return False, None
            elif status == 'cancelled':
                print("\n[!] ä»»åŠ¡è¢«å–æ¶ˆ")
                return False, None
            
            time.sleep(2)  # æ¯2ç§’è½®è¯¢ä¸€æ¬¡
            
        except Exception as e:
            print(f"\n[!] è½®è¯¢å‡ºé”™: {e}")
            return False, None

def download_and_extract(task_id, output_dir, accession=None):
    """ä¸‹è½½ç»“æœå¹¶è§£å‹ã€‚

    æŠŠæœ€ç»ˆçš„ nii / nii.gz æ–‡ä»¶æ”¾åˆ° output_dir/<AccessionNumber>/ ä¸‹ï¼ˆå¹³é“ºï¼Œä¸åœ¨åˆ›å»ºé¢å¤–é¡¶å±‚ç›®å½•ï¼‰ã€‚
    å¦‚æœæœªæä¾› accessionï¼Œåˆ™ä½¿ç”¨ task_id ä½œä¸ºç›®å½•åï¼ˆå‘åå…¼å®¹ï¼‰ã€‚
    """
    download_url = API_DOWNLOAD(task_id)
    target_zip = os.path.join(output_dir, f"result_{task_id}.zip")

    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨ï¼ˆWindows ä¸‹éœ€è¦å…ˆåˆ›å»ºï¼Œå¦åˆ™ä¸´æ—¶ç›®å½•åˆ›å»ºä¼šå¤±è´¥ï¼‰
    os.makedirs(output_dir, exist_ok=True)

    # ä½¿ç”¨ä¸´æ—¶ç›®å½•è§£å‹ï¼Œç„¶åå°† nii æ–‡ä»¶ç§»åŠ¨åˆ°æœ€ç»ˆç›®å½•ï¼ˆé¿å…åµŒå¥—ä¸€å±‚ï¼‰
    tmp_dir = tempfile.mkdtemp(prefix=f"tmp_extract_{task_id}_", dir=output_dir)
    final_dir_name = str(accession) if accession else str(task_id)
    final_dir = os.path.join(output_dir, final_dir_name)

    print(f"[*] æ­£åœ¨ä¸‹è½½ç»“æœåˆ°: {target_zip}")

    try:
        with requests.get(download_url, stream=True) as r:
            r.raise_for_status()
            with open(target_zip, 'wb') as f:
                for chunk in r.iter_content(chunk_size=8192):
                    f.write(chunk)

        print(f"[+] ä¸‹è½½å®Œæˆï¼Œæ­£åœ¨è§£å‹åˆ°ä¸´æ—¶ç›®å½•: {tmp_dir}")

        with zipfile.ZipFile(target_zip, 'r') as zip_ref:
            zip_ref.extractall(tmp_dir)

        # åˆ›å»ºç›®æ ‡ç›®å½•
        os.makedirs(final_dir, exist_ok=True)

        # å°†æ‰€æœ‰ nii / nii.gz æ–‡ä»¶ä»ä¸´æ—¶ç›®å½•ç§»åŠ¨åˆ° final_dirï¼ˆå¹³é“ºï¼‰
        moved_any = False
        for root, dirs, files in os.walk(tmp_dir):
            for fname in files:
                if fname.lower().endswith('.nii') or fname.lower().endswith('.nii.gz'):
                    src = os.path.join(root, fname)
                    dest = os.path.join(final_dir, fname)

                    # å¦‚æœç›®æ ‡å·²å­˜åœ¨ï¼Œæ·»åŠ åç¼€é¿å…è¦†ç›–
                    if os.path.exists(dest):
                        base, ext = os.path.splitext(fname)
                        counter = 1
                        while True:
                            new_name = f"{base}_{counter}{ext}"
                            dest = os.path.join(final_dir, new_name)
                            if not os.path.exists(dest):
                                break
                            counter += 1

                    shutil.move(src, dest)
                    moved_any = True

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ° nii æ–‡ä»¶ï¼Œåˆ™å°†æ•´ä¸ªè§£å‹å†…å®¹ç§»åŠ¨åˆ° final_dirï¼ˆä¿æŒåŸç»“æ„ï¼‰
        if not moved_any:
            # ç§»åŠ¨æ‰€æœ‰é¡¶å±‚å†…å®¹ä¸‹ç§»åˆ° final_dir
            for item in os.listdir(tmp_dir):
                s = os.path.join(tmp_dir, item)
                d = os.path.join(final_dir, item)
                if os.path.exists(d):
                    # å†²çªæ—¶ï¼Œå°è¯•é‡å‘½å
                    base, ext = os.path.splitext(item)
                    counter = 1
                    while True:
                        new_name = f"{base}_{counter}{ext}"
                        d = os.path.join(final_dir, new_name)
                        if not os.path.exists(d):
                            break
                        counter += 1
                shutil.move(s, d)

        print(f"[+] å¤„ç†å®Œæˆã€‚æ–‡ä»¶ä½äº: {final_dir}")
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶å’Œ zip
        try:
            os.remove(target_zip)
        except Exception:
            pass
        try:
            shutil.rmtree(tmp_dir)
        except Exception:
            pass

        return True
    except Exception as e:
        print(f"[!] ä¸‹è½½æˆ–è§£å‹å¤±è´¥: {e}")
        # å°è¯•æ¸…ç†ä¸´æ—¶ç›®å½•å’Œ zip
        try:
            if os.path.exists(target_zip):
                os.remove(target_zip)
        except Exception:
            pass
        try:
            if os.path.exists(tmp_dir):
                shutil.rmtree(tmp_dir)
        except Exception:
            pass
        return False

def main(cli_args=None):
    """æäº¤å•ä¸ª accession çš„ä»»åŠ¡å¹¶ä¸‹è½½ç»“æœã€‚

    å¦‚æœ cli_args ä¸º Noneï¼Œåˆ™ä»å‘½ä»¤è¡Œè§£æå‚æ•°å¹¶åœ¨ç»“æŸåè¿”å›ï¼›
    å¦‚æœä¼ å…¥ argparse.Namespaceï¼Œåˆ™ä½¿ç”¨è¯¥å‚æ•°å¹¶è¿”å›å¸ƒå°”è¡¨ç¤ºæˆåŠŸ/å¤±è´¥ã€‚
    """
    if cli_args is None:
        parser = argparse.ArgumentParser(description="DICOMä¸‹è½½å®¢æˆ·ç«¯æµ‹è¯•å·¥å…·")
        parser.add_argument("accession", help="AccessionNumber (ä¾‹å¦‚: Z25043000836)")
        parser.add_argument("--output_dir", default="./downloads", help="ä¸‹è½½ç»“æœå­˜æ”¾ç›®å½•")
        parser.add_argument("--format", choices=['nifti', 'npz'], default='nifti', help="è¾“å‡ºæ ¼å¼ (nifti æˆ– npz)")
        args = parser.parse_args()
    else:
        args = cli_args

    print(f"ğŸš€ å¯åŠ¨ä»»åŠ¡: AccessionNumber={args.accession}, æ ¼å¼={args.format}")

    # æ­¥éª¤1: æäº¤ä»»åŠ¡
    payload = {
        "accession_number": args.accession,
        "options": {
            "output_format": args.format,
            "auto_organize": True,
            "auto_metadata": True
        }
    }

    try:
        response = requests.post(API_SINGLE, json=payload)
        if response.status_code != 200:
            print(f"[!] æäº¤ä»»åŠ¡å¤±è´¥ ({response.status_code}): {response.text}")
            return False

        task_id = response.json().get('task_id')
        print(f"[+] ä»»åŠ¡å·²å¯åŠ¨ï¼ŒID: {task_id}")

        # æ­¥éª¤2: è½®è¯¢çŠ¶æ€
        success, result = poll_task_status(task_id)

        if success:
            # æ­¥éª¤3: ä¸‹è½½ï¼ˆå°† accession ä¼ å…¥ä»¥ä¾¿æŒ‰ AccessionNumber å‘½åç›®å½•ï¼‰
            ok = download_and_extract(task_id, args.output_dir, accession=args.accession)
            return bool(ok)
        else:
            return False

    except Exception as e:
        print(f"[!] é€šä¿¡å¤±è´¥: {e}")
        return False

PROGRESS_FILENAME = ".download_progress.json"


def load_progress(output_dir):
    path = os.path.join(output_dir, PROGRESS_FILENAME)
    if not os.path.exists(path):
        return set(), {}
    try:
        with open(path, 'r', encoding='utf-8') as f:
            data = json.load(f)
            completed = data.get('completed', [])
            timings = data.get('timings', {})
            # ensure timings are floats
            timings = {str(k): float(v) for k, v in timings.items()}
            return set(completed), timings
    except Exception:
        return set(), {}


def save_progress(output_dir, completed_set, timings_dict=None):
    os.makedirs(output_dir, exist_ok=True)
    path = os.path.join(output_dir, PROGRESS_FILENAME)
    try:
        payload = {'completed': sorted(list(completed_set))}
        if timings_dict:
            # convert timings to simple serializable map
            payload['timings'] = {str(k): float(v) for k, v in timings_dict.items()}
        with open(path, 'w', encoding='utf-8') as f:
            json.dump(payload, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"[!] æ— æ³•ä¿å­˜è¿›åº¦: {e}")


def download_list(acc_list, output_dir="./downloads", fmt='nifti'):
    """æ‰¹é‡ä¸‹è½½å¤šä¸ª AccessionNumber çš„ç»“æœï¼Œå¹¶æ”¯æŒæ–­ç‚¹ç»­ä¼ ã€‚

    è¿›åº¦è®°å½•ä¿å­˜åœ¨ output_dir/.download_progress.jsonï¼Œç¨‹åºåœ¨æ¯æ¬¡æˆåŠŸä¸‹è½½åæ›´æ–°è¯¥æ–‡ä»¶ã€‚
    """
    completed, timings = load_progress(output_dir)
    total = len(acc_list)
    # timings: dict accession->seconds (float)

    for accession in tqdm(acc_list):
        if str(accession) in completed:
            tqdm.write(f"\n--- è·³è¿‡ï¼ˆå·²å®Œæˆï¼‰ AccessionNumber: {accession} ---")
            continue
        tqdm.write(f"\n=== å¤„ç† AccessionNumber: {accession} ===")
        main_args = argparse.Namespace(
            accession=str(accession),
            output_dir=output_dir,
            format=fmt
        )
        # è®¡æ—¶å¹¶æ‰§è¡Œ
        start_t = time.time()
        ok = main(main_args)
        elapsed = time.time() - start_t

        if ok:
            # ä»…åœ¨æˆåŠŸä¸‹è½½å¹¶è§£å‹åæ ‡è®°ä¸ºå®Œæˆ
            completed.add(str(accession))
            timings[str(accession)] = elapsed
            # è®¡ç®—å¹³å‡é€Ÿåº¦ï¼ˆç§’/accï¼‰åŸºäºæ‰€æœ‰å·²çŸ¥ timings
            all_times = list(timings.values())
            avg_sec = sum(all_times) / len(all_times) if all_times else elapsed
            remaining = total - len(completed)
            remaining_sec = avg_sec * remaining
            eta = datetime.now() + timedelta(seconds=remaining_sec)

            save_progress(output_dir, completed, timings)
            tqdm.write(f"[+] æ ‡è®°ä¸ºå·²å®Œæˆ: {accession} (è€—æ—¶ {elapsed:.2f} s)")
            tqdm.write(f"    å¹³å‡: {avg_sec:.2f} s/accessionï¼›å‰©ä½™: {remaining}ï¼Œé¢„è®¡å®Œæˆ: {eta.strftime('%Y-%m-%d %H:%M:%S')}")
        else:
            tqdm.write(f"[!] å¤„ç†å¤±è´¥ï¼Œå°†åœ¨ä¸‹æ¬¡ç»§ç»­å°è¯•: {accession}")


if __name__ == "__main__":
    df=pd.read_excel('input/selected_samples_details_filtered.xlsx')
    acc_list=df['å½±åƒå·'].tolist()
    download_list(acc_list)