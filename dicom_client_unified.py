# -*- coding: utf-8 -*-
#!/usr/bin/env python3
"""
ç»Ÿä¸€ç‰ˆDICOMä¸‹è½½å’Œå¤„ç†å®¢æˆ·ç«¯
ç›´æ¥ä»PACSä¸‹è½½å¹¶å¤„ç†DICOMæ–‡ä»¶ï¼Œæ— éœ€HTTPä¸­é—´å±‚å’ŒZIPæ‰“åŒ…
"""

import os
import json
import time
import shutil
from pathlib import Path
import pandas as pd
import pydicom
import numpy as np
from collections import defaultdict
import re
import nibabel as nib
from datetime import datetime
import sys
from pynetdicom import AE, evt, AllStoragePresentationContexts
from pynetdicom.sop_class import (
    StudyRootQueryRetrieveInformationModelFind,
    StudyRootQueryRetrieveInformationModelMove
)
from pydicom.dataset import Dataset

def get_base_path():
    """è·å–ç¨‹åºè¿è¡Œæ—¶çš„æ ¹ç›®å½•è·¯å¾„ï¼Œå…¼å®¹ PyInstaller æ‰“åŒ…"""
    if hasattr(sys, '_MEIPASS'):
        return sys._MEIPASS
    return os.path.abspath(".")

class DICOMDownloadClient:
    """ç»Ÿä¸€ç‰ˆDICOMä¸‹è½½å®¢æˆ·ç«¯ï¼Œç›´æ¥ä¸PACSé€šä¿¡"""
    
    def __init__(self):
        """åˆå§‹åŒ–å®¢æˆ·ç«¯"""
        # PACSé…ç½®ï¼ˆä»ç¯å¢ƒå˜é‡åŠ è½½ï¼Œæä¾›é»˜è®¤å€¼ï¼‰
        self.pacs_config = {
            'PACS_IP': os.getenv('PACS_IP', '172.17.250.192'),
            'PACS_PORT': int(os.getenv('PACS_PORT', 2104)),
            'CALLING_AET': os.getenv('CALLING_AET', 'WMX01'),
            'CALLED_AET': os.getenv('CALLED_AET', 'pacsFIR'),
            'CALLING_PORT': int(os.getenv('CALLING_PORT', 1103))
        }
        
        # åˆå§‹åŒ–AE
        self.ae = AE(ae_title=self.pacs_config['CALLING_AET'])
        self.ae.add_requested_context(StudyRootQueryRetrieveInformationModelFind)
        self.ae.add_requested_context(StudyRootQueryRetrieveInformationModelMove)
        self.ae.network_timeout = 300
        self.ae.acse_timeout = 30
        self.ae.dimse_timeout = 300
        
        # åŠ è½½DICOMå­—æ®µåˆ—è¡¨
        self.modality_keywords = self._load_keywords()
        
        # å…¼å®¹æ€§å±æ€§
        self.session_id = "dummy_session"
        self.username = os.getenv('DICOM_USERNAME', '')
        self.role = os.getenv('DICOM_ROLE', 'admin')
        # optional progress callback to report MR_clean progress: function(message, stage)
        self.progress_callback = None
    
    def _load_keywords(self, tags_dir="dicom_tags"):
        """åŠ è½½ä¸åŒæ¨¡æ€çš„DICOMå­—æ®µåˆ—è¡¨"""
        keywords_map = {}
        default_keywords = [
            "Modality", "StudyDate", "StudyInstanceUID", "SeriesInstanceUID",
            "PatientID", "AccessionNumber", "SeriesNumber", "SeriesDescription",
            "BodyPartExamined", "Manufacturer", "ManufacturerModelName"
        ]
        
        try:
            if not os.path.exists(tags_dir):
                # å°è¯•ä½¿ç”¨æ—§çš„keywords.jsonä½œä¸ºé»˜è®¤
                keywords_path = os.path.join(get_base_path(), "keywords.json")
                if os.path.exists(keywords_path):
                    with open(keywords_path, 'r', encoding='utf-8') as f:
                        self.tag_mappings['DEFAULT'] = json.load(f)
                    print(f"âš ï¸  {self.tags_dir} not found, using keywords.json as default")
                else:
                    print(f"âš ï¸  {tags_dir} not found, using built-in default keywords")
                return {'default': default_keywords}

            # åŠ è½½æ‰€æœ‰JSONæ–‡ä»¶
            for filename in os.listdir(tags_dir):
                if filename.endswith('.json'):
                    modality = filename.replace('.json', '').upper()
                    try:
                        with open(os.path.join(tags_dir, filename), 'r', encoding='utf-8') as f:
                            keywords_map[modality] = json.load(f)
                        print(f"âœ… Loaded {modality} modality keywords ({len(keywords_map[modality])} items)")
                    except Exception as e:
                        print(f"âŒ Failed to load {filename}: {e}")
            
            # ç¡®ä¿æœ‰é»˜è®¤å€¼
            if 'MR' in keywords_map:
                keywords_map['default'] = keywords_map['MR']
            elif 'DEFAULT' in keywords_map:
                keywords_map['default'] = keywords_map['DEFAULT']
            else:
                keywords_map['default'] = default_keywords
                
            return keywords_map
            
        except Exception as e:
            print(f"âŒ Failed to load keywords files: {e}")
            return {'default': default_keywords}
    
    def get_keywords(self, modality):
        """æ ¹æ®æ¨¡æ€è·å–å­—æ®µåˆ—è¡¨"""
        # å½’ä¸€åŒ–æ¨¡æ€åç§°
        modality = modality.upper()
        if modality in ['DR', 'DX', 'CR']:
            key = 'DX'
        if "MR" in modality:
            key = 'MR'
        elif modality in self.modality_keywords:
            key = modality
        else:
            key = 'default'
            
        return self.modality_keywords.get(key, self.modality_keywords.get('default', []))

    def login(self, username, password):
        """ä¿æŒæ¥å£å…¼å®¹æ€§çš„è™šæ‹Ÿç™»å½•"""
        self.username = username
        print(f"âœ… Login successful: {username} (no actual authentication required)")
        return True
    
    def logout(self):
        """ä¿æŒæ¥å£å…¼å®¹æ€§çš„è™šæ‹Ÿç™»å‡º"""
        print(f"âœ… Logout successful: {self.username}")
        return True
    
    def check_status(self):
        """æ£€æŸ¥PACSè¿æ¥çŠ¶æ€"""
        try:
            assoc = self.ae.associate(
                self.pacs_config['PACS_IP'],
                self.pacs_config['PACS_PORT'],
                ae_title=self.pacs_config['CALLED_AET']
            )
            
            if assoc.is_established:
                assoc.release()
                print("âœ… PACS connection status: OK")
                return True
            else:
                print("âŒ Unable to connect to PACS")
                return False
        except Exception as e:
            print(f"âŒ PACS connection error: {e}")
            return False
    
    def _query_series_metadata(self, accession_number):
        """æŸ¥è¯¢PACSè·å–Serieså…ƒæ•°æ®"""
        series_metadata = []
        
        try:
            assoc = self.ae.associate(
                self.pacs_config['PACS_IP'],
                self.pacs_config['PACS_PORT'],
                ae_title=self.pacs_config['CALLED_AET']
            )
            
            if not assoc.is_established:
                print("âŒ Cannot build PACS connection")
                return []
            
            try:
                # æŸ¥è¯¢Study
                study_ds = Dataset()
                study_ds.QueryRetrieveLevel = "STUDY"
                study_ds.AccessionNumber = accession_number
                study_ds.StudyInstanceUID = ""
                study_ds.PatientID = ""
                study_ds.PatientName = ""
                study_ds.StudyDate = ""
                
                print(f"ğŸ” Query AccessionNumber: {accession_number}")
                responses = assoc.send_c_find(study_ds, StudyRootQueryRetrieveInformationModelFind)
                
                studies = {}
                for (status, identifier) in responses:
                    if status and status.Status in [0xFF00, 0xFF01]:
                        if identifier and hasattr(identifier, 'StudyInstanceUID'):
                            study_uid = str(identifier.StudyInstanceUID)
                            studies[study_uid] = {
                                'PatientID': str(identifier.PatientID) if hasattr(identifier, 'PatientID') else '',
                                'PatientName': str(identifier.PatientName) if hasattr(identifier, 'PatientName') else '',
                                'StudyDate': str(identifier.StudyDate) if hasattr(identifier, 'StudyDate') else '',
                                'AccessionNumber': accession_number
                            }
                
                if not studies:
                    print(f"âš ï¸  Can't Find AccessionNumber: {accession_number}")
                    return []
                
                # æŸ¥è¯¢æ¯ä¸ªStudyçš„Series
                for study_uid, study_info in studies.items():
                    series_ds = Dataset()
                    series_ds.QueryRetrieveLevel = "SERIES"
                    series_ds.StudyInstanceUID = study_uid
                    series_ds.SeriesInstanceUID = ""
                    series_ds.SeriesNumber = ""
                    series_ds.SeriesDescription = ""
                    series_ds.Modality = ""
                    
                    responses = assoc.send_c_find(series_ds, StudyRootQueryRetrieveInformationModelFind)
                    
                    for (status, identifier) in responses:
                        if status and status.Status in [0xFF00, 0xFF01]:
                            if identifier and hasattr(identifier, 'SeriesInstanceUID'):
                                series_info = dict(study_info)
                                series_info.update({
                                    'StudyInstanceUID': study_uid,
                                    'SeriesInstanceUID': str(identifier.SeriesInstanceUID),
                                    'SeriesNumber': str(identifier.SeriesNumber) if hasattr(identifier, 'SeriesNumber') else '0',
                                    'SeriesDescription': str(identifier.SeriesDescription) if hasattr(identifier, 'SeriesDescription') else 'Unknown',
                                    'Modality': str(identifier.Modality) if hasattr(identifier, 'Modality') else ''
                                })
                                series_metadata.append(series_info)
                
                print(f"ğŸ“Š Find {len(series_metadata)} Series")
                
            finally:
                assoc.release()
                
        except Exception as e:
            print(f"âŒ Query metadata failed: {e}")
        
        return series_metadata
    
    def download_study(self, accession_number, output_dir=".", custom_folder_name=None):
        """Download Study data (directly from PACS, no ZIP generation)"""
        print(f"ğŸ” Downloading AccessionNumber: {accession_number}")
        
        # æŸ¥è¯¢Seriesä¿¡æ¯
        series_metadata = self._query_series_metadata(accession_number)
        if not series_metadata:
            print(f"âŒ No data found for: {accession_number}")
            return None
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        timestamp = time.strftime('%Y%m%d_%H%M%S')
        if custom_folder_name:
            output_path = os.path.join(output_dir, custom_folder_name)
        else:
            output_path = os.path.join(output_dir, f"{accession_number}_{timestamp}")
        
        os.makedirs(output_path, exist_ok=True)
        
        # å­˜å‚¨çŠ¶æ€
        storage_state = {'current_path': '', 'files_received': 0}
        
        def handle_store(event):
            """å¤„ç†C-STOREè¯·æ±‚"""
            try:
                dataset = event.dataset
                dataset.file_meta = event.file_meta
                
                # ä¿å­˜æ–‡ä»¶
                sop_instance_uid = dataset.SOPInstanceUID
                filename = f"{sop_instance_uid}.dcm"
                filepath = os.path.join(storage_state['current_path'], filename)
                
                os.makedirs(storage_state['current_path'], exist_ok=True)
                dataset.save_as(filepath, write_like_original=False)
                
                storage_state['files_received'] += 1
                if storage_state['files_received'] % 10 == 0:
                    print(f"   Received {storage_state['files_received']} files...")
                
                return 0x0000
            except Exception as e:
                print(f"âŒ Failed saving DICOM file: {e}")
                return 0xA700
        
        # å¯åŠ¨C-STORE SCP
        ae_scp = AE(ae_title=self.pacs_config['CALLING_AET'])
        ae_scp.supported_contexts = AllStoragePresentationContexts
        ae_scp.add_requested_context(StudyRootQueryRetrieveInformationModelMove)
        
        server = ae_scp.start_server(
            ('', self.pacs_config['CALLING_PORT']),
            block=False,
            evt_handlers=[(evt.EVT_C_STORE, handle_store)]
        )
        
        try:
            # å»ºç«‹C-MOVEè¿æ¥
            assoc = self.ae.associate(
                self.pacs_config['PACS_IP'],
                self.pacs_config['PACS_PORT'],
                ae_title=self.pacs_config['CALLED_AET']
            )
            
            if not assoc.is_established:
                print("âŒ Unable to establish PACS association")
                return None
            
            try:
                # ä¸‹è½½æ¯ä¸ªSeries
                for i, series in enumerate(series_metadata):
                    series_num = series.get('SeriesNumber', f'Series{i+1}')
                    series_desc = series.get('SeriesDescription', 'Unknown')
                    series_dir = os.path.join(output_path, f"{series_num:0>3}_{self._sanitize_folder_name(series_desc)}")
                    
                    storage_state['current_path'] = series_dir
                    
                    print(f"ğŸ“¥ Downloading series {i+1}/{len(series_metadata)}: {series_num} - {series_desc}")
                    
                    # å‘é€C-MOVEè¯·æ±‚
                    move_ds = Dataset()
                    move_ds.QueryRetrieveLevel = 'SERIES'
                    move_ds.StudyInstanceUID = series['StudyInstanceUID']
                    move_ds.SeriesInstanceUID = series['SeriesInstanceUID']
                    
                    responses = assoc.send_c_move(
                        move_ds,
                        self.pacs_config['CALLING_AET'],
                        query_model=StudyRootQueryRetrieveInformationModelMove
                    )
                    
                    for (status, identifier) in responses:
                        if status and status.Status == 0x0000:
                            pass
                    
                    time.sleep(0.5)  # çŸ­æš‚å»¶è¿Ÿ
                
            finally:
                assoc.release()
                
        except Exception as e:
            print(f"âŒ Download error: {e}")
            return None
        finally:
            server.shutdown()
        
        print(f"âœ… Download complete! Received {storage_state['files_received']} files")
        print(f"ğŸ“ Files saved to: {output_path}")
        
        return output_path if storage_state['files_received'] > 0 else None
    
    def extract_zip(self, zip_filepath, extract_dir=None):
        """ä¿æŒæ¥å£å…¼å®¹æ€§ï¼Œç›´æ¥è¿”å›è·¯å¾„ï¼ˆå› ä¸ºä¸å†æœ‰ZIPæ–‡ä»¶ï¼‰"""
        return zip_filepath
    
    def _is_dicom_file(self, filepath):
        """åˆ¤æ–­æ˜¯å¦ä¸ºDICOMæ–‡ä»¶"""
        try:
            with open(filepath, 'rb') as f:
                f.seek(128)
                dicm = f.read(4)
                if dicm == b'DICM':
                    return True
            
            pydicom.dcmread(filepath, force=True, stop_before_pixels=True)
            return True
        except:
            return False
    
    def _sanitize_folder_name(self, name):
        """æ¸…ç†æ–‡ä»¶å¤¹åç§°"""
        if not name:
            return "Unknown"
        
        name = re.sub(r'[<>:"/\\|?*]', '_', str(name))
        name = name.strip()
        
        if len(name) > 50:
            name = name[:50]
        
        return name if name else "Unknown"
    
    def organize_dicom_files(self, extract_dir, organized_dir=None, output_format='nifti'):
        """æŒ‰Seriesæ•´ç†DICOMæ–‡ä»¶å¹¶è½¬æ¢ä¸ºæŒ‡å®šæ ¼å¼ (nifti æˆ– npz)"""
        if organized_dir is None:
            organized_dir = os.path.join(extract_dir, "organized")
        
        # å¤„ç†å¯èƒ½çš„æ—§ç‰ˆå¸ƒå°”å‚æ•°å…¼å®¹æ€§
        if output_format is True:
            output_format = 'nifti'
        elif output_format is False:
            output_format = None

        os.makedirs(organized_dir, exist_ok=True)
        
        print(f"ğŸ“‹ Organizing DICOM files (format: {output_format})...")
        print(f"ğŸ“‚ Source directory: {extract_dir}")
        print(f"ğŸ“‚ Organized directory: {organized_dir}")
        
        series_info = {}
        processed_files = 0
        
        # éå†å·²ä¸‹è½½çš„Seriesç›®å½•
        for series_folder in os.listdir(extract_dir):
            if series_folder == "organized":
                continue
                
            series_path = os.path.join(extract_dir, series_folder)
            if not os.path.isdir(series_path):
                continue
            
            # ç»Ÿè®¡DICOMæ–‡ä»¶
            dicom_files = []
            for file in os.listdir(series_path):
                filepath = os.path.join(series_path, file)
                if os.path.isfile(filepath) and self._is_dicom_file(filepath):
                    dicom_files.append(filepath)
            
            if dicom_files:
                processed_files += len(dicom_files)
                series_info[series_folder] = {
                    'path': series_path,
                    'file_count': len(dicom_files),
                    'files': dicom_files
                }
                
                # æ‰§è¡Œè½¬æ¢
                if output_format == 'nifti':
                    self.convert_dicom_to_nifti(series_path, series_folder)
                elif output_format == 'npz':
                    self._convert_to_npz(series_path, series_folder)
        
        print(f"âœ… DICOM organization complete! Processed {processed_files} files")
        
        # å°†åŸç›®å½•ç§»åŠ¨åˆ°organizedä¸‹
        for series_folder, info in series_info.items():
            src_path = info['path']
            dst_path = os.path.join(organized_dir, series_folder)
            if src_path != dst_path:
                shutil.move(src_path, dst_path)
                info['path'] = dst_path
        
        return organized_dir, series_info
    
    def convert_dicom_to_nifti(self, series_dir, series_name):
        """å°†DICOMåºåˆ—è½¬æ¢ä¸ºNIfTIæ ¼å¼"""
        try:
            print(f"   ğŸ”„ Converting {series_name} to NIfTI...")
            
            # å°è¯•ä½¿ç”¨dcm2niix
            nifti_result = self._convert_with_dcm2niix(series_dir, series_name)
            if nifti_result and nifti_result.get('success'):
                return nifti_result
            
            # ä½¿ç”¨Pythonåº“è½¬æ¢
            print(f"   âš ï¸  dcm2niix not available, trying Python libraries...")
            nifti_result = self._convert_with_python_libs(series_dir, series_name)
            return nifti_result
            
        except Exception as e:
            print(f"   âŒ NIfTI conversion failed: {e}")
            return {'success': False, 'error': str(e)}
    
    def _convert_to_npz(self, series_dir, series_name):
        """å°†DICOMåºåˆ—è½¬æ¢ä¸ºNPZæ ¼å¼ï¼Œå¹¶æŒ‰ç…§è¦æ±‚è§„èŒƒåŒ–æ–¹å‘"""
        try:
            print(f"   ğŸ”„ Converting {series_name} to NPZ (Normalized)...")
            
            # Step 1: å…ˆç”Ÿæˆ NIfTI ä½œä¸ºä¸­é—´æ–‡ä»¶ï¼Œä»¥ä¾¿åˆ©ç”¨å…¶æˆç†Ÿçš„æ–¹å‘å¤„ç†é€»è¾‘
            nifti_res = self._convert_with_dcm2niix(series_dir, series_name)
            if not (nifti_res and nifti_res.get('success')):
                nifti_res = self._convert_with_python_libs(series_dir, series_name)
            
            if not (nifti_res and nifti_res.get('success')):
                return {'success': False, 'error': 'Failed to generate base volume for NPZ'}
            
            # Step 2: åŠ è½½ NIfTI å¹¶è¿›è¡Œè§„èŒƒåŒ–å¤„ç†
            output_files = []
            if nifti_res.get('conversion_mode') == 'individual':
                # 2D æ¨¡æ€ (DR/DX/MG)
                for nii_file in nifti_res.get('output_files', []):
                    nii_path = os.path.join(series_dir, nii_file)
                    npz_file = nii_file.replace('.nii.gz', '.npz').replace('.nii', '.npz')
                    npz_path = os.path.join(series_dir, npz_file)
                    
                    self._normalize_and_save_npz(nii_path, npz_path)
                    output_files.append(npz_file)
                    if os.path.exists(nii_path): os.remove(nii_path)
            else:
                # 3D æ¨¡æ€ (CT/MR)
                nii_file = nifti_res.get('output_file')
                nii_path = os.path.join(series_dir, nii_file)
                npz_file = nii_file.replace('.nii.gz', '.npz').replace('.nii', '.npz')
                npz_path = os.path.join(series_dir, npz_file)
                
                self._normalize_and_save_npz(nii_path, npz_path)
                output_files.append(npz_file)
                if os.path.exists(nii_path): os.remove(nii_path)
                
            return {
                'success': True,
                'method': 'npz_normalized',
                'output_files': output_files
            }
            
        except Exception as e:
            print(f"   âŒ NPZ conversion failed: {e}")
            return {'success': False, 'error': str(e)}

    def _normalize_and_save_npz(self, nii_path, npz_path):
        """åŠ è½½NIfTIï¼Œåˆ©ç”¨DICOMæ–¹å‘ä¿¡æ¯è§„èŒƒåŒ–å¹¶ä¿å­˜ä¸ºNPZ"""
        # åŠ è½½ NIfTI
        img = nib.load(nii_path)
        # è½¬ä¸º RAS (Right, Anterior, Superior) åæ ‡ç³»ï¼Œæ­¤æ­¥éª¤å·²ç»¼åˆ DICOM Tag ä¸­çš„æ–¹å‘ä¿¡æ¯
        img_canonical = nib.as_closest_canonical(img)
        data = img_canonical.get_fdata()
        
        # æŒ‰ç…§ç”¨æˆ·è¦æ±‚è¿›è¡Œç¿»è½¬:
        # 1. Zè½´: Head to Feet (Superior -> Inferior). RAS ä¸­ Z+ ä¸º Superiorï¼Œæ•…ç¿»è½¬ axis 2.
        # 2. X,Yè½´: ä»°å§ä½æ¨ªæ–­ä½ (X: Right->Left, Y: Anterior->Posterior).
        #    - RAS ä¸­ X+ ä¸º Rightï¼Œæ•…ç¿»è½¬ axis 0 å¾—åˆ° Right->Left.
        #    - RAS ä¸­ Y+ ä¸º Anteriorï¼Œæ•…ç¿»è½¬ axis 1 å¾—åˆ° Anterior->Posterior.
        data = data[::-1, ::-1, ::-1]
        
        # è½¬ç½®ä¸º [Z, Y, X] æ ¼å¼ (Depth, Height, Width)
        # è¿™æ · data[0] æ˜¯æœ€ä¸Šå±‚(Head)ï¼Œä¸”å¹³é¢å†…æ»¡è¶³ä»°å§ä½æ¨ªæ–­ä½è§†è§’
        data = np.transpose(data, (2, 1, 0))
        
        # å‹ç¼©ä¿å­˜
        np.savez_compressed(npz_path, data=data.astype(np.float32))
    
    def _convert_with_dcm2niix(self, series_dir, series_name):
        """ä½¿ç”¨dcm2niixå·¥å…·è½¬æ¢"""
        try:
            import subprocess
            
            # æ£€æŸ¥dcm2niixæ˜¯å¦å¯ç”¨
            try:
                subprocess.run(['dcm2niix', '-h'], capture_output=True, check=True)
            except (subprocess.CalledProcessError, FileNotFoundError):
                return {'success': False, 'error': 'dcm2niix not available'}
            
            # è·å–åºåˆ—ä¸­çš„DICOMæ–‡ä»¶
            dicom_files = []
            for file in os.listdir(series_dir):
                filepath = os.path.join(series_dir, file)
                if file.endswith('.dcm') and os.path.isfile(filepath):
                    dicom_files.append(filepath)
            
            if not dicom_files:
                return {'success': False, 'error': 'No DICOM files found'}
            
            # è¯»å–ç¬¬ä¸€ä¸ªæ–‡ä»¶åˆ¤æ–­Modality
            first_dcm = pydicom.dcmread(dicom_files[0], force=True)
            modality = getattr(first_dcm, 'Modality', '')
            
            output_name = self._sanitize_folder_name(series_name)
            
            if modality in ['DR', 'MG', 'DX']:
                # DR/MG/DXç±»å‹ï¼šæ¯ä¸ªæ–‡ä»¶å•ç‹¬è½¬æ¢
                print(f"   â„¹ï¸  Detected {modality} modality, converting each DICOM to NIfTI")
                
                success_count = 0
                output_files = []
                
                for idx, dcm_file in enumerate(dicom_files):
                    temp_dir = None  # åˆå§‹åŒ–ä¸´æ—¶ç›®å½•å˜é‡
                    try:
                        # åˆ›å»ºä¸´æ—¶ç›®å½•å­˜æ”¾å•ä¸ªæ–‡ä»¶
                        temp_dir = os.path.join(series_dir, f'temp_{idx}')
                        os.makedirs(temp_dir, exist_ok=True)
                        
                        # å¤åˆ¶å•ä¸ªæ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
                        temp_dcm = os.path.join(temp_dir, os.path.basename(dcm_file))
                        shutil.copy2(dcm_file, temp_dcm)
                        
                        # ä¸ºæ¯ä¸ªæ–‡ä»¶ç”Ÿæˆå”¯ä¸€çš„è¾“å‡ºå
                        file_output_name = f"{output_name}_{idx+1:04d}"
                        
                        cmd = [
                            'dcm2niix',
                            '-m', 'y',
                            '-f', file_output_name,
                            '-o', series_dir,
                            '-z', 'y',
                            '-b', 'n',
                            temp_dir
                        ]
                        
                        result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)
                        
                        if result.returncode == 0:
                            # æŸ¥æ‰¾ç”Ÿæˆçš„NIfTIæ–‡ä»¶
                            nifti_file = f"{file_output_name}.nii.gz"
                            if os.path.exists(os.path.join(series_dir, nifti_file)):
                                output_files.append(nifti_file)
                                success_count += 1
                        
                        # æ¯å¤„ç†10ä¸ªæ–‡ä»¶è¾“å‡ºä¸€æ¬¡è¿›åº¦
                        if (idx + 1) % 10 == 0:
                            print(f"      Converted {idx + 1}/{len(dicom_files)} files...")
                        
                    except Exception as e:
                        print(f"      âš ï¸  Failed converting file {idx+1}: {e}")
                    finally:
                        # æ¸…ç†ä¸´æ—¶ç›®å½•
                        if temp_dir and os.path.exists(temp_dir):
                            shutil.rmtree(temp_dir, ignore_errors=True)
                
                if success_count > 0:
                    print(f"   âœ… dcm2niix conversion succeeded: {success_count}/{len(dicom_files)} files")
                    
                    # åˆ é™¤åŸå§‹DICOMæ–‡ä»¶
                    for dcm_file in dicom_files:
                        try:
                            os.remove(dcm_file)
                        except:
                            pass
                    
                    return {
                        'success': True,
                        'method': 'dcm2niix',
                        'modality': modality,
                        'conversion_mode': 'individual',
                        'output_files': output_files,
                        'file_count': success_count
                    }
                else:
                    return {'success': False, 'error': 'No files converted successfully'}
            
            else:
                # éDR/MG/DXç±»å‹ï¼šæ•´ä¸ªåºåˆ—è½¬æ¢ä¸ºä¸€ä¸ªæ–‡ä»¶ï¼ˆåŸé€»è¾‘ï¼‰
                print(f"   â„¹ï¸  {modality} modality: converting entire series to a single NIfTI file")
                
                cmd = [
                    'dcm2niix',
                    '-m', 'y',
                    '-f', output_name,
                    '-o', series_dir,
                    '-z', 'y',
                    '-b', 'n',
                    series_dir
                ]
                
                result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
                
                if result.returncode == 0:
                    nifti_files = [f for f in os.listdir(series_dir) if f.endswith(('.nii.gz', '.nii'))]
                    if nifti_files:
                        print(f"   âœ… dcm2niix conversion succeeded: {nifti_files[0]}")
                        
                        # åˆ é™¤åŸå§‹DICOMæ–‡ä»¶
                        for file in os.listdir(series_dir):
                            if file.endswith('.dcm'):
                                try:
                                    os.remove(os.path.join(series_dir, file))
                                except:
                                    pass
                        
                        return {
                            'success': True,
                            'method': 'dcm2niix',
                            'modality': modality,
                            'conversion_mode': 'series',
                            'output_file': nifti_files[0]
                        }
                
                return {'success': False, 'error': result.stderr}
                
        except Exception as e:
            return {'success': False, 'error': str(e)}


    def _convert_with_python_libs(self, series_dir, series_name):
        """ä½¿ç”¨Pythonåº“è½¬æ¢DICOMåˆ°NIfTI"""
        try:
            dicom_files = []
            for file in os.listdir(series_dir):
                filepath = os.path.join(series_dir, file)
                if self._is_dicom_file(filepath):
                    dicom_files.append(filepath)
            
            if not dicom_files:
                return {'success': False, 'error': 'No DICOM files found'}
            
            # è¯»å–ç¬¬ä¸€ä¸ªæ–‡ä»¶åˆ¤æ–­Modality
            first_dcm = pydicom.dcmread(dicom_files[0], force=True)
            modality = getattr(first_dcm, 'Modality', '')
            
            if modality in ['DR', 'MG', 'DX']:
                # DR/MG/DX: convert each file individually
                print(f"   â„¹ï¸  Detected {modality} modality; converting each DICOM file to NIfTI")
                
                success_count = 0
                output_files = []
                
                for idx, dcm_file in enumerate(dicom_files):
                    try:
                        dcm = pydicom.dcmread(dcm_file, force=True)
                        
                        if not hasattr(dcm, 'pixel_array'):
                            print(f"      âš ï¸  File {idx+1} has no pixel data")
                            continue
                        
                        pixel_data = dcm.pixel_array
                        
                        # å¤„ç†æ•°æ®ç±»å‹
                        if pixel_data.dtype == np.uint16 and dcm.get('PixelRepresentation', 0) == 1:
                            pixel_data = pixel_data.astype(np.int16)
                        
                        # è·å–åƒç´ é—´è·
                        pixel_spacing = getattr(dcm, 'PixelSpacing', [1.0, 1.0])
                        slice_thickness = getattr(dcm, 'SliceThickness', 1.0)
                        
                        # åˆ›å»ºä»¿å°„çŸ©é˜µ
                        affine = np.eye(4)
                        affine[0, 0] = float(pixel_spacing[1])
                        affine[1, 1] = float(pixel_spacing[0])
                        affine[2, 2] = float(slice_thickness)
                        
                        # å¦‚æœæ˜¯2Då›¾åƒï¼Œéœ€è¦æ·»åŠ ä¸€ä¸ªç»´åº¦
                        if len(pixel_data.shape) == 2:
                            pixel_data = pixel_data[:, :, np.newaxis]
                        
                        # åˆ›å»ºNIfTIå›¾åƒ
                        nifti_img = nib.Nifti1Image(pixel_data, affine)
                        
                        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
                        output_filename = f"{self._sanitize_folder_name(series_name)}_{idx+1:04d}.nii.gz"
                        output_path = os.path.join(series_dir, output_filename)
                        nib.save(nifti_img, output_path)
                        
                        output_files.append(output_filename)
                        success_count += 1
                        
                        # æ¯å¤„ç†10ä¸ªæ–‡ä»¶è¾“å‡ºä¸€æ¬¡è¿›åº¦
                        if (idx + 1) % 10 == 0:
                            print(f"      Converted {idx + 1}/{len(dicom_files)} files...")
                        
                    except Exception as e:
                        print(f"      âš ï¸  Failed converting file {idx+1}: {e}")
                        continue
                
                if success_count > 0:
                    # åˆ é™¤åŸå§‹DICOMæ–‡ä»¶
                    for dcm_file in dicom_files:
                        try:
                            os.remove(dcm_file)
                        except:
                            pass
                    
                    print(f"   âœ… Python libs conversion succeeded: {success_count}/{len(dicom_files)} files")
                    return {
                        'success': True,
                        'method': 'python_libs',
                        'modality': modality,
                        'conversion_mode': 'individual',
                        'output_files': output_files,
                        'file_count': success_count
                    }
                else:
                    return {'success': False, 'error': 'No files converted successfully'}
            
            else:
                # Non-DR/MG/DX: convert entire series to single file
                print(f"   â„¹ï¸  {modality} modality: converting entire series to a single NIfTI file")
                
                # å•æ–‡ä»¶å¤„ç†
                if len(dicom_files) == 1:
                    dcm = first_dcm
                    if not hasattr(dcm, 'pixel_array'):
                        return {'success': False, 'error': 'No pixel data'}
                    
                    pixel_data = dcm.pixel_array
                    pixel_spacing = getattr(dcm, 'PixelSpacing', [1.0, 1.0])
                    slice_thickness = getattr(dcm, 'SliceThickness', 1.0)
                    
                    affine = np.eye(4)
                    affine[0, 0] = float(pixel_spacing[1])
                    affine[1, 1] = float(pixel_spacing[0])
                    affine[2, 2] = float(slice_thickness)
                    
                    nifti_img = nib.Nifti1Image(pixel_data, affine)
                    output_filename = f"{self._sanitize_folder_name(series_name)}.nii.gz"
                    output_path = os.path.join(series_dir, output_filename)
                    nib.save(nifti_img, output_path)
                    
                    # åˆ é™¤åŸå§‹DICOMæ–‡ä»¶
                    for file in dicom_files:
                        try:
                            os.remove(file)
                        except:
                            pass
                    
                    print(f"   âœ… Python libs conversion succeeded: {output_filename}")
                    return {
                        'success': True,
                        'method': 'python_libs',
                        'modality': modality,
                        'conversion_mode': 'series',
                        'output_file': output_filename
                    }
                
                # å¤šæ–‡ä»¶3Då¤„ç†
                slice_info = []
                for filepath in dicom_files:
                    try:
                        dcm = pydicom.dcmread(filepath, force=True)
                        if hasattr(dcm, 'ImagePositionPatient'):
                            z_pos = float(dcm.ImagePositionPatient[2])
                        elif hasattr(dcm, 'SliceLocation'):
                            z_pos = float(dcm.SliceLocation)
                        else:
                            z_pos = 0
                        slice_info.append((z_pos, filepath, dcm))
                    except:
                        continue
                
                if not slice_info:
                    return {'success': False, 'error': 'Could not sort slices'}
                
                slice_info.sort(key=lambda x: x[0])
                
                slices = []
                for _, _, dcm in slice_info:
                    if hasattr(dcm, 'pixel_array'):
                        slices.append(dcm.pixel_array)
                
                if not slices:
                    return {'success': False, 'error': 'No pixel data found'}
                
                volume = np.stack(slices, axis=2)
                
                pixel_spacing = getattr(first_dcm, 'PixelSpacing', [1.0, 1.0])
                
                if len(slice_info) > 1:
                    slice_thickness = abs(slice_info[1][0] - slice_info[0][0])
                else:
                    slice_thickness = getattr(first_dcm, 'SliceThickness', 1.0)
                
                affine = np.eye(4)
                affine[0, 0] = float(pixel_spacing[1])
                affine[1, 1] = float(pixel_spacing[0])
                affine[2, 2] = float(slice_thickness)
                
                nifti_img = nib.Nifti1Image(volume, affine)
                output_filename = f"{self._sanitize_folder_name(series_name)}.nii.gz"
                output_path = os.path.join(series_dir, output_filename)
                nib.save(nifti_img, output_path)
                
                # åˆ é™¤åŸå§‹DICOMæ–‡ä»¶
                for file in dicom_files:
                    try:
                        os.remove(file)
                    except:
                        pass
                
                print(f"   âœ… Python libs conversion succeeded: {output_filename} ({len(slices)} slices)")
                return {
                    'success': True,
                    'method': 'python_libs',
                    'modality': modality,
                    'conversion_mode': 'series',
                    'output_file': output_filename,
                    'slice_count': len(slices)
                }
                
        except Exception as e:
            return {'success': False, 'error': str(e)}
    
    def extract_dicom_metadata(self, organized_dir, output_excel=None):
        """æå–DICOMå…ƒæ•°æ®å¹¶ä¿å­˜ä¸ºExcelæ–‡ä»¶"""
        if output_excel is None:
            timestamp = time.strftime('%Y%m%d_%H%M%S')
            metadata_dir = os.path.join(os.path.dirname(organized_dir), "metadata")
            os.makedirs(metadata_dir, exist_ok=True)
            output_excel = os.path.join(metadata_dir, f"dicom_metadata_{timestamp}.xlsx")
        
        print(f"ğŸ“Š Extracting DICOM metadata...")
        
        all_metadata = []
        
        # éå†organizedç›®å½•
        for series_folder in os.listdir(organized_dir):
            series_path = os.path.join(organized_dir, series_folder)
            
            if not os.path.isdir(series_path):
                continue
            
            print(f"ğŸ“‚ Processing series: {series_folder}")
            
            # è·å–DICOMæ–‡ä»¶ï¼ˆæˆ–æŸ¥æ‰¾å‰©ä½™çš„.dcmæ–‡ä»¶ï¼‰
            dicom_files = []
            for file in os.listdir(series_path):
                filepath = os.path.join(series_path, file)
                if file.endswith('.dcm') and os.path.isfile(filepath):
                    dicom_files.append(filepath)
            
            # å¦‚æœæ²¡æœ‰DICOMæ–‡ä»¶ï¼Œå°è¯•æŸ¥æ‰¾NIfTIæ–‡ä»¶ä»¥è·å–åŸºæœ¬ä¿¡æ¯
            if not dicom_files:
                nifti_files = [f for f in os.listdir(series_path) if f.endswith(('.nii.gz', '.nii'))]
                if nifti_files:
                    metadata = {
                        'SeriesFolder': series_folder,
                        'ConvertedToNIfTI': 'Yes',
                        'NIfTIFile': nifti_files[0],
                        'TotalFilesInSeries': 1
                    }
                    all_metadata.append(metadata)
                continue
            
            # å…ˆè¯»å–ç¬¬ä¸€ä¸ªæ–‡ä»¶åˆ¤æ–­Modality
            try:
                sample_file = dicom_files[0]
                dcm = pydicom.dcmread(sample_file, force=True)
                modality = getattr(dcm, 'Modality', '')
                
                # åˆ¤æ–­æ˜¯å¦éœ€è¦éå†æ‰€æœ‰æ–‡ä»¶
                need_read_all = modality in ['DR', 'MG', 'DX']
                
                if need_read_all:
                    print(f"   â„¹ï¸  Detected {modality} modality; will read all {len(dicom_files)} DICOM files")
                    
                    # éå†æ‰€æœ‰DICOMæ–‡ä»¶
                    for idx, dicom_file in enumerate(dicom_files):
                        try:
                            dcm = pydicom.dcmread(dicom_file, force=True)
                            
                            metadata = {
                                'SeriesFolder': series_folder,
                                'FileName': os.path.basename(dicom_file),
                                'FileIndex': idx + 1,
                                'TotalFilesInSeries': len(dicom_files)
                            }
                            
                            # è·å–å¯¹åº”æ¨¡æ€çš„å­—æ®µåˆ—è¡¨
                            current_keywords = self.get_keywords(modality)
                            
                            # æå–å…³é”®å­—æ®µ
                            for keyword in current_keywords:
                                try:
                                    value = getattr(dcm, keyword, None)
                                    if value is not None:
                                        if hasattr(value, '__len__') and not isinstance(value, str):
                                            if len(value) == 1:
                                                value = value[0]
                                            else:
                                                value = str(value)
                                        elif hasattr(value, 'value'):
                                            value = value.value
                                        metadata[keyword] = str(value)
                                    else:
                                        metadata[keyword] = ""
                                except:
                                    metadata[keyword] = ""
                            
                            all_metadata.append(metadata)
                            
                            # æ¯å¤„ç†10ä¸ªæ–‡ä»¶è¾“å‡ºä¸€æ¬¡è¿›åº¦
                            if (idx + 1) % 10 == 0:
                                print(f"      Processed {idx + 1}/{len(dicom_files)} files...")
                            
                        except Exception as e:
                            print(f"     âš ï¸  Failed reading file {os.path.basename(dicom_file)}: {e}")
                            continue
                else:
                    # Original logic: read only representative file
                    print(f"   â„¹ï¸  {modality} modality; reading representative file only")
                    
                    metadata = {
                        'SeriesFolder': series_folder,
                        'SampleFileName': os.path.basename(sample_file),
                        'TotalFilesInSeries': len(dicom_files),
                        'FilesReadForMetadata': 1  # æ ‡è®°åªè¯»å–äº†ä¸€ä¸ªæ–‡ä»¶
                    }
                    
                    # è·å–å¯¹åº”æ¨¡æ€çš„å­—æ®µåˆ—è¡¨
                    current_keywords = self.get_keywords(modality)
                    
                    # æå–å…³é”®å­—æ®µ
                    for keyword in current_keywords:
                        try:
                            value = getattr(dcm, keyword, None)
                            if value is not None:
                                if hasattr(value, '__len__') and not isinstance(value, str):
                                    if len(value) == 1:
                                        value = value[0]
                                    else:
                                        value = str(value)
                                elif hasattr(value, 'value'):
                                    value = value.value
                                metadata[keyword] = str(value)
                            else:
                                metadata[keyword] = ""
                        except:
                            metadata[keyword] = ""
                    
                    all_metadata.append(metadata)
                    
            except Exception as e:
                print(f"     âŒ Failed processing series: {e}")
                
                continue
        
        if not all_metadata:
            print("âŒ No metadata extracted")
            return None
        
        # åˆ›å»ºDataFrameå¹¶ä¿å­˜ä¸ºExcel
        try:
            df = pd.DataFrame(all_metadata)
            
            # é‡æ–°æ’åˆ—åˆ—çš„é¡ºåº
            column_order = []
            
            # ä¼˜å…ˆæ˜¾ç¤ºçš„åˆ—
            priority_columns = ['SeriesFolder', 'FileName', 'SampleFileName', 'FileIndex', 
                            'TotalFilesInSeries', 'FilesReadForMetadata']
            for col in priority_columns:
                if col in df.columns:
                    column_order.append(col)
            
            # é‡è¦çš„DICOMå­—æ®µ
            important_fields = ['PatientID', 'AccessionNumber', 'StudyDate', 'Modality',
                            'SeriesNumber', 'SeriesDescription', 'InstanceNumber']
            
            for field in important_fields:
                if field in df.columns and field not in column_order:
                    column_order.append(field)
            
            # æ·»åŠ å‰©ä½™çš„åˆ—
            for col in df.columns:
                if col not in column_order:
                    column_order.append(col)
            
            df = df[column_order]
            
            # ä¿å­˜Excelï¼Œåˆ›å»ºå¤šä¸ªå·¥ä½œè¡¨
            with pd.ExcelWriter(output_excel, engine='openpyxl') as writer:
                # ä¸»æ•°æ®è¡¨
                df.to_excel(writer, sheet_name='DICOM_Metadata', index=False)
                
                # åˆ›å»ºæ±‡æ€»è¡¨ï¼ˆæŒ‰Seriesæ±‡æ€»ï¼‰
                summary_data = []
                for series_folder in df['SeriesFolder'].unique():
                    series_df = df[df['SeriesFolder'] == series_folder]
                    summary_row = {
                        'SeriesFolder': series_folder,
                        'FileCount': len(series_df),
                        'Modality': series_df['Modality'].iloc[0] if 'Modality' in series_df.columns else '',
                        'SeriesDescription': series_df['SeriesDescription'].iloc[0] if 'SeriesDescription' in series_df.columns else '',
                        'PatientID': series_df['PatientID'].iloc[0] if 'PatientID' in series_df.columns else '',
                        'AccessionNumber': series_df['AccessionNumber'].iloc[0] if 'AccessionNumber' in series_df.columns else '',
                        'StudyDate': series_df['StudyDate'].iloc[0] if 'StudyDate' in series_df.columns else ''
                    }
                    summary_data.append(summary_row)
                
                if summary_data:
                    summary_df = pd.DataFrame(summary_data)
                    summary_df.to_excel(writer, sheet_name='Series_Summary', index=False)
                
                # è°ƒæ•´åˆ—å®½
                for sheet_name in writer.sheets:
                    worksheet = writer.sheets[sheet_name]
                    for column in worksheet.columns:
                        max_length = 0
                        column_letter = column[0].column_letter
                        for cell in column:
                            try:
                                if len(str(cell.value)) > max_length:
                                    max_length = len(str(cell.value))
                            except:
                                pass
                        adjusted_width = min(max_length + 2, 50)
                        worksheet.column_dimensions[column_letter].width = adjusted_width
            
            # ç»Ÿè®¡ä¿¡æ¯
            total_files_read = len(df)
            dr_mg_dx_series = df[df['Modality'].isin(['DR', 'MG', 'DX'])]['SeriesFolder'].nunique() if 'Modality' in df.columns else 0
            
            print(f"âœ… Metadata extraction complete!")
            print(f"ğŸ“„ Excel file: {output_excel}")
            print(f"ğŸ“Š Total records: {total_files_read}")
            if dr_mg_dx_series > 0:
                print(f"ğŸ“‹ DR/MG/DX series count: {dr_mg_dx_series} (all files read)")

            self._append_mr_cleaned_sheet(df, output_excel)
            
            return output_excel
            
        except Exception as e:
            print(f"âŒ Failed saving Excel file: {e}")
            return None

    def _append_mr_cleaned_sheet(self, df: pd.DataFrame, output_excel: str) -> None:
        """å¯¹ MR è®°å½•åšæ²»ç†/è§„èŒƒåŒ–ï¼Œå¹¶å†™å›åˆ°åŒä¸€ä¸ª Excel çš„ MR_Cleaned sheetã€‚"""
        try:
            if df is None or df.empty or 'Modality' not in df.columns:
                return

            mr_df = df[df['Modality'].astype(str).str.upper() == 'MR'].copy()
            if mr_df.empty:
                return

            print(f"\nğŸ”¬ MR_clean: processing {len(mr_df)} MR records...")

            from MR_clean import process_mri_dataframe

            # forward optional progress callback
            try:
                cleaned_df = process_mri_dataframe(mr_df, progress_callback=self.progress_callback)
            except TypeError:
                # fallback for older MR_clean signature
                cleaned_df = process_mri_dataframe(mr_df)

            with pd.ExcelWriter(
                output_excel,
                engine='openpyxl',
                mode='a',
                if_sheet_exists='replace',
            ) as writer:
                cleaned_df.to_excel(writer, sheet_name='MR_Cleaned', index=False)

            print("âœ… MR_clean: MR_Cleaned sheet written.")
        except Exception as e:
            print(f"âš ï¸  MR_clean skipped/failed: {e}")
    
    def process_complete_workflow(self, accession_number, base_output_dir="./downloads",
                                auto_extract=True, auto_organize=True, auto_metadata=True,
                                keep_zip=True, keep_extracted=False, output_format='nifti'):
        """å®Œæ•´çš„å·¥ä½œæµç¨‹ï¼šä¸‹è½½ -> æ•´ç† -> è½¬æ¢ -> æå–å…ƒæ•°æ®"""
        print(f"\n{'='*80}")
        print(f"ğŸš€ Starting full DICOM processing workflow")
        print(f"ğŸ“‹ AccessionNumber: {accession_number}")
        print(f"{'='*80}")
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(base_output_dir, exist_ok=True)
        
        # æ­¥éª¤1: ä¸‹è½½DICOMæ–‡ä»¶
        print(f"\nğŸ“¥ Step 1: Download DICOM files")
        download_dir = self.download_study(accession_number, base_output_dir)
        if not download_dir:
            print("âŒ Download failed, workflow terminated")
            return None
        
        results = {
            'accession_number': accession_number,
            'zip_file': download_dir,  # ä¿æŒæ¥å£å…¼å®¹æ€§
            'extract_dir': download_dir,  # ä¿æŒæ¥å£å…¼å®¹æ€§
            'success': False
        }
        
        if auto_organize:
            # æ­¥éª¤2: æ•´ç†DICOMæ–‡ä»¶
            print(f"\nğŸ“ Step 2: Organize DICOM files by series (format: {output_format})")
            organized_dir, series_info = self.organize_dicom_files(download_dir, output_format=output_format)
            if not organized_dir:
                print("âŒ File organization failed, workflow terminated")
                return results
            
            results['organized_dir'] = organized_dir
            results['series_info'] = series_info
            
            if auto_metadata:
                # æ­¥éª¤3: æå–å…ƒæ•°æ®
                print(f"\nğŸ“Š Step 3: Extract DICOM metadata")
                excel_file = self.extract_dicom_metadata(organized_dir)
                if excel_file:
                    results['excel_file'] = excel_file
                    results['success'] = True
                else:
                    print("âš ï¸  Metadata extraction failed, previous steps completed")
        
        # æ‰“å°æœ€ç»ˆç»“æœ
        print(f"\n{'='*80}")
        if results['success']:
            print(f"ğŸ‰ Workflow completed!")
            print(f"ğŸ“ Organized directory: {results.get('organized_dir', 'N/A')}")
            print(f"ğŸ“„ Excel file: {results.get('excel_file', 'N/A')}")
            print(f"ğŸ“Š Series count: {len(results.get('series_info', {}))}")
        else:
            print(f"âš ï¸  Workflow partially completed")
        print(f"{'='*80}")
        
        return results


def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºå®Œæ•´å·¥ä½œæµç¨‹"""
    print("ğŸ¥ Unified DICOM download and processing system")
    print("ğŸ“¡ Direct PACS server connection")
    
    # åˆ›å»ºå®¢æˆ·ç«¯
    client = DICOMDownloadClient()
    
    # æ£€æŸ¥PACSçŠ¶æ€
    if not client.check_status():
        print("âŒ PACS unavailable, exiting")
        return
    
    # è™šæ‹Ÿç™»å½•ï¼ˆä¿æŒæ¥å£å…¼å®¹æ€§ï¼‰
    client.login("admin", "admin123")
    
    try:
        # æ‰§è¡Œå®Œæ•´å·¥ä½œæµç¨‹
        accession_number = "Z25043000836"  # ç¤ºä¾‹AccessionNumber
        
        results = client.process_complete_workflow(
            accession_number=accession_number,
            base_output_dir="./dicom_processed",
            auto_extract=True,  # ä¿æŒå…¼å®¹æ€§å‚æ•°
            auto_organize=True,
            auto_metadata=True,
            keep_zip=False,     # ä¿æŒå…¼å®¹æ€§å‚æ•°
            keep_extracted=False,
            output_format='nifti'  # å¯é€‰ 'nifti' æˆ– 'npz'
        )
        
        if results and results['success']:
            print(f"\nğŸŠ Processing complete! See the following files:")
            if 'excel_file' in results:
                print(f"   ğŸ“„ Metadata Excel: {results['excel_file']}")
            if 'organized_dir' in results:
                print(f"   ğŸ“ Organized directory: {results['organized_dir']}")
        else:
            print(f"\nâŒ Processing not fully successful")
    
    finally:
        # è™šæ‹Ÿç™»å‡º
        client.logout()


if __name__ == "__main__":
    main()